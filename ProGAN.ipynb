{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, Input, LeakyReLU, Layer, UpSampling2D,Add,Flatten,AveragePooling2D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from math import sqrt\n",
    "from numpy import load\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "import math\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from functools import partial\n",
    "from scipy.linalg import sqrtm\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormalization(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(PixelNormalization,self).__init__(**kwargs)\n",
    "    def call(self,x):\n",
    "        value = x**2\n",
    "        mean = K.mean(value, axis = -1, keepdims=True)\n",
    "        x = x/K.sqrt(mean + 1.0e-8)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = K.variable(alpha, name='ws_alpha')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "                'alpha' : 0.0\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStdev(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    "\n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # calculate the mean value for each pixel across channels\n",
    "        mean = K.mean(inputs, axis=0, keepdims=True)\n",
    "        # calculate the squared differences between pixel values and mean\n",
    "        squ_diffs = K.square(inputs - mean)\n",
    "        # calculate the average of the squared differences (variance)\n",
    "        mean_sq_diff = K.mean(squ_diffs, axis=0, keepdims=True)\n",
    "        # add a small value to avoid a blow-up when we calculate stdev\n",
    "        mean_sq_diff += 1e-8\n",
    "        # square root of the variance (stdev)\n",
    "        stdev = K.sqrt(mean_sq_diff)\n",
    "        # calculate the mean standard deviation across each pixel coord\n",
    "        mean_pix = K.mean(stdev, keepdims=True)\n",
    "        # scale this up to be the size of one input feature map for each sample\n",
    "        shape = K.shape(inputs)\n",
    "        output = K.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
    "        # concatenate with the output\n",
    "        combined = K.concatenate([inputs, output], axis=-1)\n",
    "        return combined\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # create a copy of the input shape as a list\n",
    "        input_shape = list(input_shape)\n",
    "        # add one to the channel dimension (assume channels-last)\n",
    "        input_shape[-1] += 1\n",
    "        # convert list to a tuple\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wgan Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_loss_function(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generator_block(old_model):\n",
    "    # weight initialization\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = tf.keras.constraints.max_norm(1.0)\n",
    "    # get the end of the last block\n",
    "    block_end = old_model.layers[-2].output\n",
    "    # upsample, and define new block\n",
    "#     with strategy.scope():\n",
    "    upsampling = UpSampling2D()(block_end)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    # add new output layer\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    # define model\n",
    "    model1 = Model(old_model.input, out_image)\n",
    "    # get the output layer from old model\n",
    "    out_old = old_model.layers[-1]\n",
    "    # connect the upsampling to the old output layer\n",
    "    out_image2 = out_old(upsampling)\n",
    "    # define new output image as the weighted sum of the old and new models\n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    # define model\n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]\n",
    "\n",
    "\n",
    "\n",
    "def get_loss(args):\n",
    "    new_feature, content_feature = args[0], args[1]\n",
    "    loss = 0\n",
    "    for i in range(len(new_feature)):\n",
    "        loss += K.mean(K.square(new_feature[i] - content_feature[i]))\n",
    "    return loss\n",
    "\n",
    "\n",
    "    # define generator models\n",
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    # weight initialization\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = tf.keras.constraints.max_norm(1.0)\n",
    "    model_list = list()\n",
    "    # base model latent input\n",
    "#     with strategy.scope():\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    # linear scale up to activation maps\n",
    "    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((in_dim, in_dim, 128))(g)\n",
    "    #########################################\n",
    "    # conv 4x4, input block\n",
    "    g = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    # conv 3x3\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    # conv 1x1, output block\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    #########################################3\n",
    "    # define model\n",
    "    model = Model(in_latent, out_image)\n",
    "    # store model\n",
    "    model_list.append([model, model])\n",
    "    # create submodels\n",
    "    for i in range(1, n_blocks):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "\n",
    "        models = add_generator_block(old_model)\n",
    "        # store model\n",
    "        model_list.append(models)\n",
    "    return model_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build discriminator backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_discriminator_block(old_model, n_input_layers=3):\n",
    "    # weight initialization\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = tf.keras.constraints.max_norm(1.0)\n",
    "    # get shape of existing model\n",
    "#     with strategy.scope():\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    # define new input shape as double the size\n",
    "    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
    "    in_image = Input(shape=input_shape)\n",
    "    # define new input processing layer\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # define new block\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = AveragePooling2D()(d)\n",
    "    # d = RoiPoolingConv(2)(d)\n",
    "    block_new = d\n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model1 = Model(in_image, d)\n",
    "    # compile model\n",
    "#     logdir = 'd_log'\n",
    "#     callback1 = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "#         model1.compile(loss=wasserstein_loss, optimizer=RMSprop(lr=0.001, clipnorm=1.0))\n",
    "    model1.compile(loss=wasserstein_loss, optimizer=RMSprop(lr=0.001))\n",
    "    # downsample the new larger image\n",
    "    downsample = AveragePooling2D()(in_image)\n",
    "    # connect old input processing to downsampled new input\n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    # fade in output of old model input layer with new input\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model2 = Model(in_image, d)\n",
    "    # compile model\n",
    "#     model2.compile(loss=wasserstein_loss, optimizer=RMSprop(lr=0.001,clipnorm=1.0))\n",
    "    return [model1, model2]\n",
    "\n",
    "\n",
    "    # define the discriminator models for each image resolution\n",
    "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
    "    # weight initialization\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    # weight constraint\n",
    "    const = tf.keras.constraints.max_norm(1.0)\n",
    "    model_list = list()\n",
    "    # base model input\n",
    "#     with strategy.scope():\n",
    "    in_image = Input(shape=input_shape)\n",
    "    # conv 1x1\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # conv 3x3 (output block)\n",
    "    d = MinibatchStdev()(d)\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # conv 4x4\n",
    "    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # dense output layer\n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, out_class)\n",
    "    # compile model\n",
    "#     model.compile(loss=wasserstein_loss, optimizer=RMSprop(lr=0.001))\n",
    "    # store model\n",
    "    model_list.append([model, model])\n",
    "    # create submodels\n",
    "    for i in range(1, n_blocks):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "\n",
    "        models = add_discriminator_block(old_model)\n",
    "\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Penalty for Wgan loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        alpha = tf.random.uniform((self.batch_size, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'batch_size': self.batch_size,\n",
    "            \n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(y_true, y_pred, discriminator,gradient_penalty_weight):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "      \n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(y_pred)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = discriminator(y_pred, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [y_pred])[0]\n",
    "        # 3. Calcuate the norm of the gradients\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp*gradient_penalty_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_model(discriminator, batch_size):\n",
    "#     with strategy.scope():\n",
    "    real_input = discriminator.input\n",
    "    shape = real_input.shape[1:]\n",
    "    fake_input = Input(shape = shape)\n",
    "\n",
    "    discriminator_output_from_generator = discriminator(fake_input)\n",
    "    discriminator_output_from_real_samples = discriminator(real_input)\n",
    "\n",
    "    averaged_samples = RandomWeightedAverage(batch_size = batch_size)([real_input,\n",
    "                                            fake_input])\n",
    "#     averaged_samples_out = discriminator(averaged_samples)\n",
    "    partial_gp_loss = partial(gradient_penalty,\n",
    "                          discriminator = discriminator,\n",
    "                          gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT)\n",
    "# # Functions need names or Keras will throw an error\n",
    "    partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "\n",
    "\n",
    "    discriminator_model = Model(inputs = [real_input,fake_input], \n",
    "                  outputs = [discriminator_output_from_real_samples,discriminator_output_from_generator,averaged_samples])\n",
    "\n",
    "    discriminator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9),\n",
    "                            loss=[wasserstein_loss,\n",
    "                                  wasserstein_loss,\n",
    "                                   partial_gp_loss])\n",
    "    return discriminator_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build GAN model (generator + freeze discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_composite(discriminators, generators):\n",
    "    model_list = []\n",
    "#     with strategy.scope():\n",
    "    for i in range(len(discriminators)):\n",
    "    #     if i != len(discriminators) -1 :\n",
    "        discriminators[i][0].trainable = False\n",
    "        input = generators[i][0].output\n",
    "        output = discriminators[i][0](input)\n",
    "        model1 = Model(generators[i][0].input, output)\n",
    "        model1.compile(loss = wasserstein_loss, optimizer = RMSprop(lr=0.001))\n",
    "\n",
    "\n",
    "        discriminators[i][1].trainable = False\n",
    "        input = generators[i][1].output\n",
    "        output = discriminators[i][1](input)\n",
    "        model2 = Model(generators[i][1].input, output)\n",
    "        model2.compile(loss = wasserstein_loss, optimizer = RMSprop(lr=0.001))\n",
    "#         model2.compile(loss = wasserstein_loss, optimizer = RMSprop(lr=0.001, clipnorm=1.0))\n",
    "        model_list.append([model1, model2])\n",
    "\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(dataset):\n",
    "    X = np.array(dataset)\n",
    "    X = X.astype('float32')\n",
    "    X = (X - 127.5)/127.5\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = dataset[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update alpha in fadein model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fadein(models, step, n_steps):\n",
    "    # calculate current alpha (linear from 0 to 1)\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    # update the alpha for each model\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                K.set_value(layer.alpha, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model and plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(dir,status, g_model, latent_dim, n_samples = 25, shape = (4,4)):\n",
    "    # devise name\n",
    "#     gen_shape = g_model.output_shape\n",
    "    gen_shape = shape\n",
    "    print(gen_shape)\n",
    "    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
    "    # generate images\n",
    "    if dir == 'g_model/':\n",
    "        X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "        # normalize pixel values to the range [0,1]\n",
    "        X = (X - X.min()) / (X.max() - X.min())\n",
    "        # plot real images\n",
    "        square = int(sqrt(n_samples))\n",
    "        for i in range(n_samples):\n",
    "            plt.subplot(square, square, 1 + i)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(X[i])\n",
    "        # save plot to file\n",
    "        filename1 = 'plot_%s.png' % (name)\n",
    "        plt.savefig(filename1)\n",
    "        plt.close()\n",
    "    # save the generator model\n",
    "        filename2 = dir + 'model_%s.h5' % (name)\n",
    "        g_model.save(filename2)\n",
    "        print('>Saved: %s and %s' % (filename1, filename2))\n",
    "    else:\n",
    "        filename2 = dir + 'model_%s.h5' % (name)\n",
    "        g_model.save(filename2)\n",
    "        print('>Saved: %s' % ( filename2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for one stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch, writer,fadein=False):\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    fid_score_min = 10000\n",
    "    patient = 0\n",
    "    fid_list = []\n",
    "#     gen_shape = g_model.output_shape\n",
    "#     name = 'faded' if fadein  else 'tuned'\n",
    "#     name_model = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], name)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # update alpha for all WeightedSum layers when fading in new blocks\n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
    "        # prepare real and fake samples\n",
    "#         X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "#         X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        dummy = np.zeros((half_batch,1))\n",
    "        # update discriminator model\n",
    "#         d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "            \n",
    "#         d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        for _ in range(2):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            d_loss = d_model.train_on_batch([X_real,X_fake], [y_real,y_fake,dummy])\n",
    "        \n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        \n",
    "        z_input = generate_latent_points(latent_dim, n_batch)\n",
    "       \n",
    "        y_real2 = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "#         if isinstance(g_loss,list):\n",
    "#             g_loss = g_loss[0]\n",
    "        \n",
    "    ### Write to tensorboard\n",
    "        if i % 500 == 0 and fadein == False:\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar('d_loss',d_loss[0] , step=i)\n",
    "                writer.flush()\n",
    "#                 tf.summary.scalar('d_loss2',d_loss2 , step=i)\n",
    "#                 writer.flush()\n",
    "                tf.summary.scalar('g_loss',g_loss , step=i)\n",
    "                writer.flush()\n",
    "\n",
    "    \n",
    "        if i %  1000 == 0:\n",
    "#             print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "            print('>%d, d=%.3f, g=%.3f' % (i+1, d_loss[0], g_loss))\n",
    "#             print(\"fid_score:\", fid_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
    "    # fit the baseline model\n",
    "\n",
    "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "    # scale dataset to appropriate size\n",
    "    gen_shape = g_normal.output_shape\n",
    "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "    print('Scaled Data', scaled_data.shape)\n",
    "    # train normal or straight-through models\n",
    "    writer = tf.summary.create_file_writer(logdir = 'log_1/log_0')\n",
    "    train_epochs(g_normal, d_normal, gan_normal, scaled_data,latent_dim, e_norm[0], n_batch[0],writer, False)\n",
    "    \n",
    "    ### Save model\n",
    "    summarize_performance('g_model/','tuned', g_normal, latent_dim,shape = gen_shape)\n",
    "    summarize_performance('d_model/','tuned', d_normal, latent_dim, shape = gen_shape)\n",
    "    summarize_performance('gan_model/','tuned', gan_normal, latent_dim, shape = gen_shape)\n",
    "    \n",
    "    # process each level of growth\n",
    "    for i in range(1, len(g_models)):\n",
    "\n",
    "        # retrieve models for this level of growth\n",
    "        writer = tf.summary.create_file_writer(logdir = 'log_1/log_{}'.format(i))\n",
    "        scaled_data = []\n",
    "        \n",
    "        # scale dataset to appropriate size\n",
    "        [g_normal, g_fadein] = g_models[i]\n",
    "        [d_normal, d_fadein] = d_models[i]\n",
    "        [gan_normal, gan_fadein] = gan_models[i]\n",
    "        gen_shape = g_normal.output_shape\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        print('Scaled Data', scaled_data.shape)\n",
    "        # train fade-in models for next level of growth\n",
    "        \n",
    "        ### Save model\n",
    "        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data,latent_dim, e_fadein[i], n_batch[i],writer, True)\n",
    "        summarize_performance('g_model/','faded', g_fadein, latent_dim, shape = gen_shape)\n",
    "        summarize_performance('d_model/','faded', d_fadein, latent_dim, shape = gen_shape)\n",
    "        summarize_performance('gan_model/','faded', gan_fadein, latent_dim, shape = gen_shape)\n",
    "        # train normal or straight-through models\n",
    "        train_epochs(g_normal, d_normal, gan_normal, scaled_data,latent_dim, e_norm[i], n_batch[i],writer, False)\n",
    "        summarize_performance('g_model/','tuned', g_normal, latent_dim, shape = gen_shape)\n",
    "        summarize_performance('d_model/','tuned', d_normal, latent_dim, shape = gen_shape)\n",
    "        summarize_performance('gan_model/','tuned', gan_normal, latent_dim, shape = gen_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f4cceef79fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlatent_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# dimension of latent vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0min_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0md_models\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdefine_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# discriminator backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdis_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# discriminator model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# n_batch = [1024,1024, 1024, 512, 128, 64]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'define_generator' is not defined"
     ]
    }
   ],
   "source": [
    "latent_dims = 100 # dimension of latent vector\n",
    "g_models = define_generator(latent_dim = 100, n_blocks = 6,  in_dim = 4)\n",
    "d_models  = define_discriminator(n_blocks = 6, input_shape=(4,4,3)) # discriminator backbone\n",
    "dis_model = [] # discriminator model\n",
    "# n_batch = [1024,1024, 1024, 512, 128, 64]\n",
    "n_batch = [64,64,32,16,8,8] # batch_size\n",
    "\n",
    "\n",
    "## build discriminator \n",
    "for i in range(len(d_models)):\n",
    "    dis_model.append([build_discriminator_model(d_models[i][0],int(n_batch[i]/2)),build_discriminator_model(d_models[i][1], int(n_batch[i]/2))])\n",
    "\n",
    "## build gan model\n",
    "gan_models = define_composite(d_models, g_models)\n",
    "\n",
    "# load dataset from Celeb face dataset (replace with custom dataset)\n",
    "dataset = load_real_samples(all_faces)\n",
    "\n",
    "n_epochs = [10, 16, 16, 20, 20, 20]\n",
    "\n",
    "\n",
    "train(g_models, dis_model, gan_models, dataset, latent_dims, n_epochs, n_epochs, n_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
