{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Input,AveragePooling2D, Concatenate, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop,SGD\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array,array_to_img\n",
    "import keras\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:1\", \"/gpu:2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "# tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(PixelNormalization,self).__init__(**kwargs)\n",
    "    def call(self,x):\n",
    "        value = x**2\n",
    "        mean = K.mean(value, axis = -1, keepdims=True)\n",
    "        x = x/K.sqrt(mean + 1.0e-8)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(tf.keras.layers.Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = K.variable(alpha, name='ws_alpha')\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "                'alpha' : 0.0\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStdev(tf.keras.layers.Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    "\n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # calculate the mean value for each pixel across channels\n",
    "        mean = K.mean(inputs, axis=0, keepdims=True)\n",
    "        # calculate the squared differences between pixel values and mean\n",
    "        squ_diffs = K.square(inputs - mean)\n",
    "        # calculate the average of the squared differences (variance)\n",
    "        mean_sq_diff = K.mean(squ_diffs, axis=0, keepdims=True)\n",
    "        # add a small value to avoid a blow-up when we calculate stdev\n",
    "        mean_sq_diff += 1e-8\n",
    "        # square root of the variance (stdev)\n",
    "        stdev = K.sqrt(mean_sq_diff)\n",
    "        # calculate the mean standard deviation across each pixel coord\n",
    "        mean_pix = K.mean(stdev, keepdims=True)\n",
    "        # scale this up to be the size of one input feature map for each sample\n",
    "        shape = K.shape(inputs)\n",
    "        output = K.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
    "        # concatenate with the output\n",
    "        combined = K.concatenate([inputs, output], axis=-1)\n",
    "        return combined\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # create a copy of the input shape as a list\n",
    "        input_shape = list(input_shape)\n",
    "        # add one to the channel dimension (assume channels-last)\n",
    "        input_shape[-1] += 1\n",
    "        # convert list to a tuple\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, **kwargs):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        alpha = tf.random.uniform((self.batch_size, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'batch_size': self.batch_size,\n",
    "            \n",
    "        })\n",
    "        return config\n",
    "    \n",
    "def gradient_penalty(y_true, y_pred, discriminator,gradient_penalty_weight):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "      \n",
    "        print(\"===\", y_true, y_pred)\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(y_pred)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = discriminator(y_pred, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [y_pred])[0]\n",
    "        # 3. Calcuate the norm of the gradients\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp*gradient_penalty_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "class Cut_VGG19:\n",
    "    \"\"\"\n",
    "    Class object that fetches keras' VGG19 model trained on the imagenet dataset\n",
    "    and declares <layers_to_extract> as output layers. Used as feature extractor\n",
    "    for the perceptual loss function.\n",
    "    Args:\n",
    "        layers_to_extract: list of layers to be declared as output layers.\n",
    "        patch_size: integer, defines the size of the input (patch_size x patch_size).\n",
    "    Attributes:\n",
    "        loss_model: multi-output vgg architecture with <layers_to_extract> as output layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size, layers_to_extract):\n",
    "        self.patch_size = patch_size\n",
    "        self.input_shape = (patch_size,) * 2 + (3,)\n",
    "        self.layers_to_extract = layers_to_extract\n",
    "        \n",
    "        if len(self.layers_to_extract) > 0:\n",
    "            self._cut_vgg()\n",
    "    \n",
    "    def _cut_vgg(self):\n",
    "        \"\"\"\n",
    "        Loads pre-trained VGG, declares as output the intermediate\n",
    "        layers selected by self.layers_to_extract.\n",
    "        \"\"\"\n",
    "        \n",
    "        vgg = VGG19(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        vgg.trainable = False\n",
    "        outputs = [vgg.layers[i].output for i in self.layers_to_extract]\n",
    "        self.model = Model([vgg.input], outputs)\n",
    "feature_extraction = Cut_VGG19(128,[5,9])   \n",
    "feature_extraction.model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fadein(models, step, n_steps):\n",
    "    # calculate current alpha (linear from 0 to 1)\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    # update the alpha for each model\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                K.set_value(layer.alpha, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGP():\n",
    "    def __init__(self,pre_train = False, **kwargs):\n",
    "        self.input_dim = (256,256,3)\n",
    "        self.optimiser = 'rmsprop'\n",
    "        self.z_dim = 256\n",
    "        self.n_batch = [64,64,32,16,4,4] # batch_size\n",
    "        self.pre_train = pre_train\n",
    "        ################ Encoder Model ########################\n",
    "        self.encoder_input = (256,256,1)\n",
    "        self.encoder_conv_filters = [8,16,32,64]\n",
    "        self.encoder_conv_kernel_size = [3,3,3,3]\n",
    "        self.encoder_conv_strides = [2,2,2,2]\n",
    "        self.encoder_batch_norm_momentum =  None\n",
    "        self.encoder_activation = 'relu'\n",
    "        self.encoder_dropout_rate = None\n",
    "        self.encoder_learning_rate = 1e-5\n",
    "        \n",
    "        ############## Conditional Layer #######################\n",
    "        self.conditional_input = (256,256,1)\n",
    "        self.conditional_conv_filters = [8,16,32]\n",
    "        self.conditional_conv_kernel_size = [3,3,3]\n",
    "        self.conditional_conv_strides = [2,2,2]\n",
    "        self.layer_concatenate = 2\n",
    "        \n",
    "        ################ Generator Model #########################\n",
    "        self.generator_initial_dense_layer_size = (4,4,256)\n",
    "        self.generator_upsample = [1,1,1]\n",
    "        self.generator_conv_filters = [128,128,3]\n",
    "        self.generator_conv_kernel_size = [4,3,1]\n",
    "        self.generator_conv_strides = [2,2,2]\n",
    "        self.generator_batch_norm_momentum =  None\n",
    "        self.generator_activation = 'leaky_relu'\n",
    "        self.generator_dropout_rate = None\n",
    "        self.generator_learning_rate = 1e-3\n",
    "        self.gen_n_blocks = len(self.n_batch)\n",
    "        \n",
    "        ################ Discriminator Model ###########################\n",
    "        self.discriminator_input_shape = (4,4,3)\n",
    "        self.discriminator_conv_filters = [128,128,128]\n",
    "        self.discriminator_conv_kernel_size = [1,3,4]\n",
    "        self.discriminator_conv_strides = [1,1,1]\n",
    "        self.discriminator_batch_norm_momentum = None\n",
    "        self.discriminator_activation = 'leaky_relu'\n",
    "        self.discriminator_dropout_rate = None\n",
    "        self.discriminator_learning_rate = 1e-3\n",
    "        self.disc_n_blocks = len(self.n_batch)\n",
    "        ###########################################\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "        self.grad_weight = 10\n",
    "        self.batch_size = 128\n",
    "        self.const = tf.keras.constraints.max_norm(1.0)\n",
    "        ############################################\n",
    "        self.n_layers_conditional = len(self.conditional_conv_filters)\n",
    "        self.n_layers_encoder = len(self.encoder_conv_filters)\n",
    "        self.n_layers_discriminator = len(self.discriminator_conv_filters)\n",
    "        self.n_layers_generator = len(self.generator_conv_filters)\n",
    "        \n",
    "        ###############################################                               \n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "        self.epoch = 0\n",
    "        ###############################################\n",
    "#         self._build_encoder()\n",
    "#         self.encoder_model.summary()\n",
    "        if self.pre_train:\n",
    "            self.g_models = []\n",
    "            self.d_models = []\n",
    "            for i in range(0, len(self.n_batch)):\n",
    "                # scale dataset to appropriate size\n",
    "                output_shape = 4*np.power(2,i)\n",
    "                print(output_shape)\n",
    "                g_normal = tf.keras.models.load_model(\"./model_save/model_proGAN/g_normal_\"+str(output_shape)+\".h5\", \\\n",
    "                                                      custom_objects={'PixelNormalization':PixelNormalization, \\\n",
    "                                                                     'MinibatchStdev': MinibatchStdev, \\\n",
    "                                                                     'WeightedSum':WeightedSum})\n",
    "                \n",
    "                g_fadein = tf.keras.models.load_model(\"./model_save/model_proGAN/g_fadein_\"+str(output_shape)+\".h5\", \\\n",
    "                                                      custom_objects={'PixelNormalization':PixelNormalization, \\\n",
    "                                                                     'MinibatchStdev': MinibatchStdev, \\\n",
    "                                                                     'WeightedSum':WeightedSum})\n",
    "                \n",
    "                d_normal = tf.keras.models.load_model(\"./model_save/model_proGAN/d_normal_\"+str(output_shape)+\".h5\", \\\n",
    "                                                      custom_objects={'AveragePooling2D':AveragePooling2D, \\\n",
    "                                                                     'MinibatchStdev': MinibatchStdev, \\\n",
    "                                                                     'RandomWeightedAverage':RandomWeightedAverage, \\\n",
    "                                                                     'WeightedSum':WeightedSum, \\\n",
    "                                                                     'wasserstein':self.wasserstein})\n",
    "                \n",
    "                d_fadein = tf.keras.models.load_model(\"./model_save/model_proGAN/d_fadein_\"+str(output_shape)+\".h5\", \\\n",
    "                                                    custom_objects={'AveragePooling2D':AveragePooling2D, \\\n",
    "                                                                   'MinibatchStdev': MinibatchStdev, \\\n",
    "                                                                   'RandomWeightedAverage':RandomWeightedAverage, \\\n",
    "                                                                    'WeightedSum':WeightedSum, \\\n",
    "                                                                   'wasserstein':self.wasserstein})\n",
    "                \n",
    "                \n",
    "                self.g_models.append([g_normal, g_fadein])\n",
    "                self.d_models.append([d_normal,d_fadein])\n",
    "\n",
    "        else:\n",
    "            self.g_models = self._build_generator()\n",
    "            self.d_models = self._build_discriminator()\n",
    "\n",
    "        self._build_adversarial()\n",
    "        LOG_DIR = \"./logs/pro_gan.log\"\n",
    "        logging.basicConfig(filename=LOG_DIR,  \n",
    "                    level=logging.DEBUG,\n",
    "                    format=\"[%(asctime)s] [%(name)s] [%(message)s]\",\n",
    "                    filemode=\"w\")\n",
    "        \n",
    "    ####################### Loss ###########################\n",
    "    def wasserstein(self, y_true, y_pred):\n",
    "        return -K.mean(y_true * y_pred)\n",
    "    \n",
    "    def get_perceptual_loss(self,y_true,y_pred):\n",
    "#         vgg_shape = y_pred.shape[1]\n",
    "#         feature_extraction = Cut_VGG19(vgg_shape,[5,9])   \n",
    "#         feature_extraction.model.trainable = False\n",
    "        content_feature = feature_extraction.model(y_true)\n",
    "        new_feature = feature_extraction.model(y_pred)\n",
    "        perceptual_loss = 0\n",
    "        weight = tf.constant([1/16,1/8], dtype = tf.float32)\n",
    "        for i in range(len(new_feature)):\n",
    "            perceptual_loss += weight[i]*K.mean(K.square(new_feature[i] - content_feature[i]))\n",
    "        l2_loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true,y_pred))\n",
    "        total_loss = perceptual_loss + 100*l2_loss\n",
    "        return total_loss\n",
    "\n",
    "    def log_normal_pdf(self,sample, mean, logvar, raxis=1):\n",
    "        log2pi = tf.math.log(2. * np.pi)\n",
    "        return tf.reduce_sum(\n",
    "          -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "          axis=raxis)\n",
    "    \n",
    "    def encoder_gen_loss(self,y_true, y_pred):\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.mean_squared_error(y_true,y_pred))\n",
    "        return reconstruction_loss\n",
    "    \n",
    "    def dummy_loss_function(self,y_true, y_pred):\n",
    "        return y_pred\n",
    "\n",
    "    ################# Activation layer #####################                                                                \n",
    "    def get_activation(self, activation):\n",
    "        if activation == 'leaky_relu':\n",
    "            layer = LeakyReLU(alpha = 0.2)\n",
    "        else:\n",
    "            layer = Activation(activation)\n",
    "        return layer\n",
    "    \n",
    "    ####################################################################\n",
    "    #################### Build Encoder Model ###########################\n",
    "    ####################################################################\n",
    "    def _build_encoder(self):\n",
    "        with strategy.scope():\n",
    "            encoder_input_layer = Input(shape=self.encoder_input, name='encoder_input')\n",
    "            x = encoder_input_layer\n",
    "            for i in range(self.n_layers_encoder):\n",
    "                x = Conv2D(\n",
    "                    filters = self.encoder_conv_filters[i]\n",
    "                    , kernel_size = self.encoder_conv_filters[i]\n",
    "                    , strides = self.encoder_conv_strides[i]\n",
    "                    , padding = 'same'\n",
    "                    , name = 'encoder_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                    ,activation='relu'\n",
    "                    )(x)\n",
    "\n",
    "                if self.encoder_dropout_rate:\n",
    "                    x = Dropout(rate = self.encoder_dropout_rate)(x)\n",
    "            x = Flatten()(x)\n",
    "\n",
    "            encoder_output = Dense(self.z_dim, activation=None, kernel_initializer = self.weight_init)(x)\n",
    "    \n",
    "            self.encoder_model = Model(encoder_input_layer, encoder_output,name=\"Encoder\")\n",
    "    ####################################################################\n",
    "    #################### Build Generator Model #########################\n",
    "    ####################################################################\n",
    "    \n",
    "    def _build_generator(self):\n",
    "        ############  generator ###############\n",
    "        #with strategy.scope():\n",
    "        generator_input_layer = Input(shape=(self.z_dim,), name='generator_input')\n",
    "        x = generator_input_layer\n",
    "        x = Dense(np.prod(self.generator_initial_dense_layer_size), kernel_initializer = self.weight_init)(x)\n",
    "\n",
    "        if self.generator_batch_norm_momentum:\n",
    "            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)       \n",
    "        x = self.get_activation(self.generator_activation)(x)\n",
    "        x = Reshape(self.generator_initial_dense_layer_size)(x)\n",
    "\n",
    "        if self.generator_dropout_rate:\n",
    "            x = Dropout(rate = self.generator_dropout_rate)(x)\n",
    "\n",
    "        ###########################################################\n",
    "        for i in range(self.n_layers_generator): \n",
    "#             x = UpSampling2D()(x)\n",
    "            x = Conv2D(\n",
    "            filters = self.generator_conv_filters[i]\n",
    "            , kernel_size = (self.generator_conv_kernel_size[i],self.generator_conv_kernel_size[i])\n",
    "            , padding = 'same'\n",
    "            , kernel_initializer = self.weight_init\n",
    "            , kernel_constraint=self.const\n",
    "            )(x)\n",
    "\n",
    "            if i < self.n_layers_generator - 1:\n",
    "                x = PixelNormalization()(x)\n",
    "                if self.generator_batch_norm_momentum:\n",
    "                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "                x = self.get_activation(self.generator_activation)(x)                \n",
    "        generator_output = x\n",
    "        generator_model = Model(generator_input_layer, generator_output,name='Generator')\n",
    "\n",
    "        #################### Store Model #######################\n",
    "        model_list = list()\n",
    "        model_list.append([generator_model, generator_model])\n",
    "        # create submodels\n",
    "        for i in range(1, self.gen_n_blocks):\n",
    "            # get prior model without the fade-on\n",
    "            old_model = model_list[i - 1][0]\n",
    "\n",
    "            # create new model for next resolution\n",
    "            models = self.add_generator_block(old_model)\n",
    "            # store model\n",
    "            model_list.append(models)\n",
    "        return model_list\n",
    "    #################### Add Generator Block ################\n",
    "    def add_generator_block(self,old_model):\n",
    "        # weight initialization\n",
    "        init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "        # weight constraint\n",
    "        const = tf.keras.constraints.max_norm(1.0)\n",
    "        # get the end of the last block\n",
    "        block_end = old_model.layers[-2].output\n",
    "        # upsample, and define new block\n",
    "        #with strategy.scope():\n",
    "        upsampling = UpSampling2D()(block_end)\n",
    "        g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "        g = PixelNormalization()(g)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "        g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "        g = PixelNormalization()(g)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "        # add new output layer\n",
    "        out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "        # define model\n",
    "        model1 = Model(old_model.input, out_image)\n",
    "        # get the output layer from old model\n",
    "        out_old = old_model.layers[-1]\n",
    "        # connect the upsampling to the old output layer\n",
    "        out_image2 = out_old(upsampling)\n",
    "        # define new output image as the weighted sum of the old and new models\n",
    "        merged = WeightedSum()([out_image2, out_image])\n",
    "        # define model\n",
    "        model2 = Model(old_model.input, merged)\n",
    "        return [model1, model2]\n",
    "        \n",
    "    ####################################################################\n",
    "    #################### Build Discriminator Model #####################\n",
    "    ####################################################################\n",
    "    def _build_discriminator(self):\n",
    "        #with strategy.scope():\n",
    "        discriminator_input = Input(shape=self.discriminator_input_shape, name='discriminator_input')\n",
    "        x = discriminator_input\n",
    "\n",
    "        for i in range(self.n_layers_discriminator):\n",
    "            x = Conv2D(\n",
    "                filters = self.discriminator_conv_filters[i]\n",
    "                , kernel_size = (self.discriminator_conv_kernel_size[i],self.discriminator_conv_kernel_size[i])\n",
    "                , strides = self.discriminator_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , kernel_initializer = self.weight_init\n",
    "                , kernel_constraint= self.const\n",
    "                )(x)\n",
    "\n",
    "            if self.discriminator_batch_norm_momentum and i > 0:\n",
    "                x = BatchNormalization(momentum = self.discriminator_batch_norm_momentum)(x)\n",
    "            x = self.get_activation(self.discriminator_activation)(x)\n",
    "            if self.discriminator_dropout_rate:\n",
    "                x = Dropout(rate = self.discriminator_dropout_rate)(x)\n",
    "            if i <self.n_layers_discriminator-1:\n",
    "                x = MinibatchStdev()(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        discriminator_output = Dense(1, activation=None\n",
    "        , kernel_initializer = self.weight_init\n",
    "        )(x)\n",
    "\n",
    "        discriminator_model = Model(discriminator_input, discriminator_output,name=\"Discriminator\")\n",
    "        model_list = list()\n",
    "\n",
    "        model_list.append([discriminator_model, discriminator_model])\n",
    "        # create submodels\n",
    "        for i in range(1, self.disc_n_blocks):\n",
    "            # get prior model without the fade-on\n",
    "            old_model = model_list[i - 1][0]\n",
    "\n",
    "            # create new model for next resolution\n",
    "            models = self.add_discriminator_block(old_model)\n",
    "            model_list.append(models)\n",
    "        return model_list\n",
    "    #################### Add Discriminator Block ################\n",
    "    def add_discriminator_block(self,old_model, n_input_layers=3):\n",
    "        # weight initialization\n",
    "        init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "        # weight constraint\n",
    "        const = tf.keras.constraints.max_norm(1.0)\n",
    "        # get shape of existing model\n",
    "        #with strategy.scope():\n",
    "        in_shape = list(old_model.input.shape)\n",
    "\n",
    "        # define new input shape as double the size\n",
    "        input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
    "        in_image = Input(shape=input_shape)\n",
    "        # define new input processing layer\n",
    "        d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        # define new block\n",
    "        d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        d = AveragePooling2D()(d)\n",
    "#         d = RoiPoolingConv(2)(d)\n",
    "        block_new = d\n",
    "        # skip the input, 1x1 and activation for the old model\n",
    "        for i in range(n_input_layers, len(old_model.layers)):\n",
    "            d = old_model.layers[i](d)\n",
    "        # define straight-through model\n",
    "        model1 = Model(in_image, d)\n",
    "        # compile model\n",
    "        model1.compile(loss=self.wasserstein, optimizer=RMSprop(lr=0.001))\n",
    "        # downsample the new larger image\n",
    "        downsample = AveragePooling2D()(in_image)\n",
    "        # connect old input processing to downsampled new input\n",
    "        block_old = old_model.layers[1](downsample)\n",
    "        block_old = old_model.layers[2](block_old)\n",
    "\n",
    "        # fade in output of old model input layer with new input\n",
    "        d = WeightedSum()([block_old, block_new])\n",
    "\n",
    "        # skip the input, 1x1 and activation for the old model\n",
    "        for i in range(n_input_layers, len(old_model.layers)):\n",
    "            d = old_model.layers[i](d)\n",
    "        # define straight-through model\n",
    "        model2 = Model(in_image, d)\n",
    "        return [model1, model2]\n",
    "   \n",
    "\n",
    "    #################### Optimize #########################\n",
    "\n",
    "    def get_opti(self, lr):\n",
    "        if self.optimiser == 'adam':\n",
    "            opti = Adam(lr=lr, beta_1=0.5)\n",
    "        elif self.optimiser == 'rmsprop':\n",
    "            opti = RMSprop(lr=lr)\n",
    "        else:\n",
    "            opti = Adam(lr=lr)\n",
    "\n",
    "        return opti\n",
    "\n",
    "\n",
    "    def set_trainable(self, m, val):\n",
    "        m.trainable = val\n",
    "        for l in m.layers:\n",
    "            l.trainable = val\n",
    "            \n",
    "    def update_fadein(self,models, step, n_steps):\n",
    "        # calculate current alpha (linear from 0 to 1)\n",
    "        alpha = step / float(n_steps - 1)\n",
    "        # update the alpha for each model\n",
    "        for model in models:\n",
    "            for layer in model.layers:\n",
    "                if isinstance(layer, WeightedSum):\n",
    "                    K.set_value(layer.alpha, alpha)\n",
    "    ####################################################################\n",
    "    #################### Build Adversarial Model #########################\n",
    "    ####################################################################\n",
    "    def build_discriminator_model(self,discriminator, batch_size):\n",
    "        #with strategy.scope():\n",
    "        real_input = discriminator.input\n",
    "        shape = real_input.shape[1:]\n",
    "        fake_input = Input(shape = shape)\n",
    "\n",
    "        discriminator_output_from_generator = discriminator(fake_input)\n",
    "        discriminator_output_from_real_samples = discriminator(real_input)\n",
    "\n",
    "        averaged_samples = RandomWeightedAverage(batch_size = batch_size)([real_input,\n",
    "                                                fake_input])\n",
    "       \n",
    "        partial_gp_loss = partial(gradient_penalty,\n",
    "                              discriminator = discriminator,\n",
    "                              gradient_penalty_weight=10)\n",
    "\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "\n",
    "\n",
    "        discriminator_model = Model(inputs = [real_input,fake_input], \n",
    "                      outputs = [discriminator_output_from_real_samples,discriminator_output_from_generator,averaged_samples])\n",
    "\n",
    "        discriminator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9),\n",
    "                                loss=[self.wasserstein,\n",
    "                                      self.wasserstein,\n",
    "                                       partial_gp_loss])\n",
    "        return discriminator_model\n",
    "    \n",
    "    def define_composite(self,discriminators, generators):\n",
    "        model_list = []\n",
    "        #with strategy.scope():\n",
    "        for i in range(len(discriminators)):\n",
    "            if i != len(discriminators)-1 :\n",
    "                discriminators[i][0].trainable = False\n",
    "                input_dis = generators[i][0].output\n",
    "                output = discriminators[i][0](input_dis)\n",
    "                model1 = Model(generators[i][0].input, output)\n",
    "                model1.compile(loss = self.wasserstein, optimizer = RMSprop(lr=0.001))\n",
    "                discriminators[i][0].trainable = True\n",
    "\n",
    "                discriminators[i][1].trainable = False\n",
    "                input_dis = generators[i][1].output\n",
    "                output = discriminators[i][1](input_dis)\n",
    "                model2 = Model(generators[i][1].input, output)\n",
    "                model2.compile(loss = self.wasserstein, optimizer = RMSprop(lr=0.001))\n",
    "                discriminators[i][1].trainable = True\n",
    "\n",
    "            else:\n",
    "                discriminators[i][0].trainable = False\n",
    "                input_dis = generators[i][0].output\n",
    "                output = discriminators[i][0](input_dis)\n",
    "                model1 = Model(generators[i][0].input, [output,input_dis])\n",
    "                model1.compile(loss = [self.wasserstein, self.get_perceptual_loss], optimizer = RMSprop(lr=0.001))\n",
    "                discriminators[i][0].trainable = True\n",
    "\n",
    "                discriminators[i][1].trainable = False\n",
    "                input_dis = generators[i][1].output\n",
    "                output = discriminators[i][1](input_dis)\n",
    "                model2 = Model(generators[i][1].input, [output,input_dis])\n",
    "                model2.compile(loss =  [self.wasserstein, self.get_perceptual_loss], optimizer = RMSprop(lr=0.001))\n",
    "                discriminators[i][1].trainable = True\n",
    "                \n",
    "            model_list.append([model1, model2])\n",
    "\n",
    "        return model_list\n",
    "    ####################################################################\n",
    "    #################### Build Adversarial Model #########################\n",
    "    ####################################################################\n",
    "    def _build_adversarial(self):\n",
    "        self.disc_models = []\n",
    "        ## build discriminator \n",
    "        for i in range(len(self.d_models)):\n",
    "            self.disc_models.append([self.build_discriminator_model(self.d_models[i][0],int(self.n_batch[i])),self.build_discriminator_model(self.d_models[i][1], int(self.n_batch[i]))])\n",
    "\n",
    "        ## build gan model\n",
    "        self.gan_models = self.define_composite(self.d_models, self.g_models)    \n",
    "    \n",
    "    def train_discriminator(self,g_model,d_model,latent_code, x_train,Y_train, batch_size):\n",
    "\n",
    "        valid = np.ones((batch_size,1))\n",
    "        fake = -np.ones((batch_size,1))\n",
    "        dummy = np.zeros((int(batch_size), 1), dtype=np.float32) # Dummy gt for gradient penalty\n",
    "  \n",
    "        #images_input = x_train\n",
    "        #latent_code = self.encoder_model.predict(images_input)\n",
    "        \n",
    "        gen_imgs = g_model.predict(latent_code)\n",
    "        \n",
    "        true_imgs = Y_train\n",
    "        d_loss = d_model.train_on_batch([true_imgs,gen_imgs],[valid, fake, dummy])\n",
    "   \n",
    "        return d_loss\n",
    "\n",
    "    def train_generator(self,gan_model,latent_code,x_train,Y_train, batch_size):\n",
    "        valid = np.ones((batch_size,1), dtype=np.float32)\n",
    "        true_images = Y_train\n",
    "        input_images = x_train\n",
    "        \n",
    "        #latencode = self.encoder_model.predict(input_images)\n",
    "        #latencode = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        \n",
    "        if type(gan_model.output)==list:\n",
    "            gans_loss = gan_model.train_on_batch(latent_code, [valid,Y_train])\n",
    "        else:\n",
    "            gans_loss = gan_model.train_on_batch(latent_code, valid)\n",
    "        return gans_loss\n",
    "    \n",
    "#     def train_encoder_gen(self,x_train,Y_train, batch_size):\n",
    "        \n",
    "#         return gans_loss\n",
    "\n",
    "    def scaled_data(self,data,input_shape):\n",
    "        images_arr = []\n",
    "        for img in data:\n",
    "            #print(img.shape)\n",
    "            img = array_to_img(img)\n",
    "            resized_img = img.resize(size=input_shape[:-1])\n",
    "            images_arr.append(img_to_array(resized_img))\n",
    "        data = np.asarray(images_arr)\n",
    "        data = (data - 127.5)/127.5\n",
    "        data = data.astype('float32')\n",
    "        return data\n",
    "    \n",
    "    def shuffle_data_batch(self,array_X,array_Y,batch_size):\n",
    "        indices = np.arange(array_X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        array_X = array_X[indices]\n",
    "        array_Y = array_Y[indices]\n",
    "        return array_X,array_Y\n",
    "    \n",
    "    def shuffle_data_batch_with_latent(self,array_latent,array_X,array_Y,batch_size):\n",
    "        indices = np.arange(array_X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        array_latent = array_latent[indices]\n",
    "        array_X = array_X[indices]\n",
    "        array_Y = array_Y[indices]\n",
    "        return array_latent,array_X,array_Y\n",
    "    \n",
    "    def split_into_chunks(self,l, n):\n",
    "        for i in range(0, l.shape[0], n):\n",
    "            yield l[i:i + n]  \n",
    "        \n",
    "    def train_epochs(self,g_model, d_model, gan_model,latent_code_train, x_train, Y_train,n_critic=5,fadein=False):\n",
    "        \n",
    "        for i in range(self.n_steps):\n",
    "            if fadein:\n",
    "                update_fadein([g_model, d_model, gan_model], i, self.n_steps)\n",
    "            x = next(x_train)\n",
    "            Y = next(Y_train)\n",
    "            latent_code = next(latent_code_train)\n",
    "            for _ in range(n_critic):\n",
    "                d_loss = self.train_discriminator(g_model,d_model,latent_code,x, Y, self.batch_size)\n",
    "            g_loss = self.train_generator(gan_model,latent_code,x ,Y , self.batch_size)\n",
    "            # Plot the progress\n",
    "            self.d_losses.append(d_loss)\n",
    "            self.g_losses.append(g_loss)\n",
    "            return d_loss,g_loss\n",
    "    def train(self,latent_code_train,latent_code_val,x_train,Y_train,x_val,Y_val, batch_size, epochs, run_folder, print_every_n_batches = 10, n_critic=2):\n",
    "        \n",
    "        for epoch in range(self.epoch, self.epoch + epochs):\n",
    "            for i in range(0, len(self.g_models)):\n",
    "                self.batch_size = self.n_batch[i]\n",
    "                latent_code_train_gan,x_train_gan,Y_train_gan = self.shuffle_data_batch_with_latent(latent_code_train,x_train,Y_train,self.batch_size)\n",
    "                self.n_steps = int(x_train.shape[0]/self.batch_size)-1\n",
    "                # scale dataset to appropriate size\n",
    "                [g_normal, g_fadein] = self.g_models[i]\n",
    "                [d_normal, d_fadein] = self.disc_models[i]\n",
    "                [gan_normal, gan_fadein] = self.gan_models[i]\n",
    "                gen_shape = g_normal.output_shape\n",
    "                Y_train_reshape = self.scaled_data(Y_train_gan, gen_shape[1:])\n",
    "                Y_train_reshape = self.split_into_chunks(Y_train_reshape,self.batch_size)\n",
    "                x_train_reshape = self.split_into_chunks(x_train_gan,self.batch_size)\n",
    "                latent_code_train_reshape = self.split_into_chunks(latent_code_train,self.batch_size)\n",
    "                # Train with fadein\n",
    "                d_loss_fadein, g_loss_fadein = self.train_epochs(g_fadein, d_fadein, gan_fadein,latent_code_train_reshape,x_train_reshape, Y_train_reshape,n_critic, True)\n",
    "                # Train without fadein\n",
    "                d_loss, g_loss = self.train_epochs(g_normal, d_normal, gan_normal,latent_code_train_reshape, x_train_reshape, Y_train_reshape,n_critic, False)\n",
    "                \n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % print_every_n_batches == 0:\n",
    "                logging.info(json.dumps({'epoch':epoch,'d_fadein_loss':d_loss_fadein,'g_fadein_loss':g_loss_fadein,'d_normal_loss':d_loss,'g_normal_loss':g_loss})) \n",
    "                print (epoch,\"=======Fadein====\",d_loss_fadein, g_loss_fadein)\n",
    "                self.sample_images(latent_code_val,x_val,Y_val,run_folder,self.g_models[-1][1], fadein = True)\n",
    "                self.sample_images(latent_code_val,x_val,Y_val,run_folder,self.g_models[-1][0], fadein = False)\n",
    "                for i in range(0, len(self.g_models)):\n",
    "                    # scale dataset to appropriate size\n",
    "                    [g_normal, g_fadein] = self.g_models[i]\n",
    "                    [d_normal, d_fadein] = self.d_models[i]\n",
    "                    #[gan_normal, gan_fadein] = GAN.gan_models[i]\n",
    "                    output_shape = g_normal.output_shape[1]\n",
    "                    g_normal.save(\"./model_save/model_proGAN/g_normal_\"+str(output_shape)+\".h5\")\n",
    "                    g_fadein.save(\"./model_save/model_proGAN/g_fadein_\"+str(output_shape)+\".h5\")\n",
    "                    d_normal.save(\"./model_save/model_proGAN/d_normal_\"+str(output_shape)+\".h5\")\n",
    "                    d_fadein.save(\"./model_save/model_proGAN/d_fadein_\"+str(output_shape)+\".h5\")\n",
    "            self.epoch+=1\n",
    "\n",
    "\n",
    "\n",
    "    def sample_images(self,latent_code_val,x_val,Y_val, run_folder, g_model, fadein = True):\n",
    "        # Test\n",
    "        r, c = 4, 4\n",
    "        output_shape = g_model.output_shape[1:]\n",
    "        y_true = Y_val[:100,:,:,:]\n",
    "        input_model = x_val[:100,:,:,:]\n",
    "        \n",
    "        #latent_code = self.encoder_model.predict(input_model)\n",
    "        latent_code = latent_code_val\n",
    "        gen_imgs = g_model.predict(latent_code)\n",
    "        # Perceptual loss\n",
    "        #perceptloss = get_perceptual_loss(y_true,gen_imgs)\n",
    "\n",
    "        indx = np.random.choice(y_true.shape[0], int(0.5*c*r) ,replace=False)\n",
    "\n",
    "        face_real = 0.5*(y_true[indx]+1)\n",
    "        #face_real = face_real[:,:,:,[2,1,0]]\n",
    "\n",
    "        gen_imgs = 0.5 * (gen_imgs[indx] + 1)\n",
    "        gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "        #gen_imgs = gen_imgs[:,:,:,[2,1,0]]\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "        #fig.suptitle(\"Perceptual loss : %.3f\" %(perceptloss))\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(int(0.5*c)):\n",
    "                axs[i,2*j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "                axs[i,2*j].axis('off')\n",
    "                axs[i,2*j+1].imshow(np.squeeze(face_real[cnt, :,:,:]))\n",
    "                axs[i,2*j+1].axis('off')\n",
    "                cnt += 1\n",
    "        \n",
    "        if fadein:\n",
    "            fig.savefig(os.path.join(run_folder, \"images_latent/sample_fadein_%d_%d.png\" % (output_shape[0],self.epoch)))\n",
    "        else:\n",
    "            fig.savefig(os.path.join(run_folder, \"images_latent/sample_normal_%d_%d.png\" % (output_shape[0],self.epoch)))\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = WGANGP(pre_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../Finger_enhancement/data_cropped/data_train/'\n",
    "with open(os.path.join(DATA_DIR,\"data_face_3571_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_fingerprint_3571_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_finger = pickle.load(input_file)\n",
    "\n",
    "    \n",
    "with open(os.path.join(DATA_DIR,\"data_face_3571_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_fingerprint_3571_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_finger = pickle.load(input_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2856, 256, 256, 3),\n",
       " (2856, 256, 256, 1),\n",
       " (715, 256, 256, 3),\n",
       " (715, 256, 256, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_face.shape,data_train_finger.shape,data_val_face.shape,data_val_finger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0 0\n",
      "255 137.0 0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(data_train_finger),np.median(data_train_finger),np.min(data_train_finger))\n",
    "print(np.max(data_train_face),np.median(data_train_face),np.min(data_train_face))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data_face_fingerprint(data_face,data_finger, num_augment_percent=0.8):\n",
    "    num_data = data_face.shape[0]\n",
    "    num_data_augment = int(data_face.shape[0]*num_augment_percent)\n",
    "    index_data = np.random.choice(data_face.shape[0],num_data_augment,replace=False)\n",
    "    \n",
    "    data_aug_face = []\n",
    "    data_aug_finger = []\n",
    "    for i in index_data:\n",
    "        data_aug_face.append(data_face[i,:,:,:])\n",
    "        data_aug_finger.append(data_finger[i,:,:,:])\n",
    "    data_aug_face = np.asarray(data_aug_face)    \n",
    "    data_aug_finger = np.asarray(data_aug_finger) \n",
    "\n",
    "    # create image data augmentation generator\n",
    "    datagen_face = ImageDataGenerator(horizontal_flip=True)\n",
    "    datagen_face.fit(data_aug_face)\n",
    "    \n",
    "    datagen_finger = ImageDataGenerator(horizontal_flip=False,height_shift_range=0.1,width_shift_range=0.1,shear_range=0.5,rotation_range=20)\n",
    "    datagen_finger.fit(data_aug_finger)\n",
    "    \n",
    "    it_face = datagen_face.flow(data_aug_face,batch_size=num_data_augment,shuffle=False)\n",
    "    it_finger = datagen_finger.flow(data_aug_finger,batch_size=num_data_augment,shuffle=False)\n",
    "    \n",
    "    results_face = np.concatenate([data_face,it_face.next()],axis=0)\n",
    "    results_finger = np.concatenate([data_finger,it_finger.next()],axis=0)\n",
    "    #np.random.shuffle(results)\n",
    "    return results_face,results_finger\n",
    "\n",
    "def augment_data_only_fingerprint(data_finger, num_augment_percent = 0.5):\n",
    "    \n",
    "    num_data = data_finger.shape[0]\n",
    "    num_data_augment = int(data_finger.shape[0]*num_augment_percent)\n",
    "    index_batch = np.arange(0,num_data_augment)\n",
    "    index_data = np.random.choice(num_data,num_data_augment,replace=False)\n",
    "    ###############################\n",
    "    data_aug_finger = []\n",
    "    for i in index_data:\n",
    "        data_aug_finger.append(data_finger[i,:,:,:])   \n",
    "    data_aug_finger = np.asarray(data_aug_finger) \n",
    "    ################################\n",
    "    datagen_finger = ImageDataGenerator(horizontal_flip=False,height_shift_range=0.2,width_shift_range=0.2,shear_range=0.1,rotation_range=20)\n",
    "    datagen_finger.fit(data_aug_finger)\n",
    "    ###############################\n",
    "    it_finger = datagen_finger.flow(data_aug_finger,batch_size=num_data_augment,shuffle=False)\n",
    "    finger_augmented = it_finger.next()\n",
    "    ################################\n",
    "    result_finger = data_finger\n",
    "    for index in zip(index_data,index_batch):\n",
    "        result_finger[index[0],:,:,:]=finger_augmented[index[1],:,:,:]\n",
    "    return result_finger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_face, data_train_finger = augment_data_face_fingerprint(data_train_face,data_train_finger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5140, 256, 256, 3),\n",
       " (5140, 256, 256, 1),\n",
       " (715, 256, 256, 3),\n",
       " (715, 256, 256, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_face.shape,data_train_finger.shape,data_val_face.shape,data_val_finger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_finger = ((data_train_finger)/np.max(data_train_finger))\n",
    "data_val_finger = ((data_val_finger)/np.max(data_val_finger))\n",
    "data_train_finger = np.where(data_train_finger > .5, 1.0, 0.0).astype('float32')\n",
    "data_val_finger = np.where(data_val_finger > .5, 1.0, 0.0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5140, 256, 256, 1), (715, 256, 256, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_finger.shape, data_val_finger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_face = ((data_train_face-127.5)/127.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5140, 256, 256, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_face = ((data_val_face-127.5)/127.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715, 256, 256, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 0.0\n",
      "1.0 0.07450981 -1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(data_train_finger),np.median(data_train_finger),np.min(data_train_finger))\n",
    "print(np.max(data_train_face),np.median(data_train_face),np.min(data_train_face))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_face = data_train_face\n",
    "val_face = data_val_face\n",
    "train_finger = data_train_finger\n",
    "val_finger = data_val_finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_latentcode,valid_latentcode,train_face,valid_face = train_test_split(data_train_latentcode[2],\n",
    "#                                                              data_train_face,\n",
    "#                                                              test_size=0.2,\n",
    "#                                                              random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5140, 256, 256, 3),\n",
       " (715, 256, 256, 3),\n",
       " (5140, 256, 256, 1),\n",
       " (715, 256, 256, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_face.shape,val_face.shape,train_finger.shape, val_finger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(data_train_finger[10],cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow((data_train_face[10]+1)*0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data train with latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data_train/data_get_latent/'\n",
    "with open(os.path.join(DATA_DIR,\"data_face_2856_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_fingerprint_2856_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_finger = pickle.load(input_file)\n",
    "\n",
    "    \n",
    "with open(os.path.join(DATA_DIR,\"data_face_2856_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_fingerprint_2856_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_finger = pickle.load(input_file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR,\"data_latentcode_2856_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_latent = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_latentcode_2856_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_latent = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_face = data_train_face\n",
    "val_face = data_val_face\n",
    "train_finger = data_train_finger\n",
    "val_finger = data_val_finger\n",
    "train_latent = data_train_latent[2]\n",
    "val_latent = data_val_latent[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_latent.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_45/random_weighted_average_1/add:0\", shape=(64, 4, 4, 3), dtype=float32)\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_45/random_weighted_average_1/add:0\", shape=(64, 4, 4, 3), dtype=float32)\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_43/random_weighted_average/add:0\", shape=(64, 4, 4, 3), dtype=float32)\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_43/random_weighted_average/add:0\", shape=(64, 4, 4, 3), dtype=float32)\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_49/random_weighted_average_3/add:0\", shape=(64, 8, 8, 3), dtype=float32)\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_49/random_weighted_average_3/add:0\", shape=(64, 8, 8, 3), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7fe9e0681d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_train_function.<locals>.train_function at 0x7fead3fe8dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_47/random_weighted_average_2/add:0\", shape=(64, 8, 8, 3), dtype=float32)\n",
      "=== Tensor(\"IteratorGetNext:4\", shape=(64, 1), dtype=float32) Tensor(\"functional_47/random_weighted_average_2/add:0\", shape=(64, 8, 8, 3), dtype=float32)\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7feac93425e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2d8cefe5b134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m GAN.train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_latent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mval_latent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mtrain_finger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mtrain_face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d7fc855797ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, latent_code_train, latent_code_val, x_train, Y_train, x_val, Y_val, batch_size, epochs, run_folder, print_every_n_batches, n_critic)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0md_loss_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_fadein\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_fadein\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_code_train_reshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_reshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Train without fadein\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                 \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_normal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_code_train_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_reshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# If at save interval => save generated image samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d7fc855797ce>\u001b[0m in \u001b[0;36mtrain_epochs\u001b[0;34m(self, g_model, d_model, gan_model, latent_code_train, x_train, Y_train, n_critic, fadein)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d7fc855797ce>\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(self, gan_model, latent_code, x_train, Y_train, batch_size)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mgans_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0mgans_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgans_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m    963\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    798\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1209\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1210\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1211\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2945\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    749\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpo9srapow.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mmean_sq_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_sq_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mmean_sq_diff\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1e-08\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mstdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_sq_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mmean_pix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Whitelisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36msqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2368\u001b[0m   \"\"\"\n\u001b[1;32m   2369\u001b[0m   \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m   \u001b[0minf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2371\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_constant_to_tensor\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m   \"\"\"\n\u001b[0;32m--> 819\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    286\u001b[0m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3466\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_from_scope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3468\u001b[0;31m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3470\u001b[0m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36munique_name\u001b[0;34m(self, name, mark_as_used)\u001b[0m\n\u001b[1;32m   4240\u001b[0m     \u001b[0;31m# Increment the number for \"name_key\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmark_as_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4242\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_names_in_use\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m       \u001b[0mbase_name_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GAN.train(\n",
    "    train_latent\n",
    "    , val_latent\n",
    "    , train_finger  \n",
    "    , train_face\n",
    "    , val_finger\n",
    "    , val_face\n",
    "    , batch_size = 4\n",
    "    , epochs = 10000\n",
    "    , run_folder = './model_save'\n",
    "    , print_every_n_batches = 20\n",
    "    , n_critic = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #gan_normal.save(\"./model_save/model_proGAN/gan_normal_\"+str(output_shape)+\".h5\")\n",
    "    #gan_fadein.save(\"./model_save/model_proGAN/gan_fadein_\"+str(output_shape)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.discriminator.save('./model_save/model/discriminator_3channel_new.h5')\n",
    "GAN.generator.save('./model_save/model/generator_3channel_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.models.load_model('./model_save/model/generator_3channel_conditional.h5',custom_objects={'get_perceptual_loss': get_perceptual_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(validate=True):    # Test\n",
    "    r, c = 4, 4\n",
    "    if validate :\n",
    "        y_true = val_face\n",
    "        x_true = val_finger\n",
    "    else:\n",
    "        y_true = train_face[900:1000,:,:,:]\n",
    "        x_true = train_finger[900:1000,:,:,:]\n",
    "    \n",
    "    latent_code = GAN.encoder_model.predict(x_true)\n",
    "    gen_imgs = GAN.generator.predict(latent_code)\n",
    "    # Perceptual loss\n",
    "    #perceptloss = get_perceptual_loss(y_true,gen_imgs)\n",
    "\n",
    "    indx = np.random.choice(y_true.shape[0], int(0.5*c*r) ,replace=False)\n",
    "\n",
    "    face_real = 0.5*(y_true[indx]+1)\n",
    "    #face_real = face_real[:,:,:,[2,1,0]]\n",
    "\n",
    "    gen_imgs = 0.5 * (gen_imgs[indx] + 1)\n",
    "    gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "    #gen_imgs = gen_imgs[:,:,:,[2,1,0]]\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "    #fig.suptitle(\"Perceptual loss : %.3f\" %(perceptloss))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(int(0.5*c)):\n",
    "            axs[i,2*j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "            axs[i,2*j].axis('off')\n",
    "            axs[i,2*j+1].imshow(np.squeeze(face_real[cnt, :,:,:]))\n",
    "            axs[i,2*j+1].axis('off')\n",
    "            cnt += 1\n",
    "\n",
    "    plt.show()\n",
    "    #fig.savefig(os.path.join('./model_save', \"images/face_gens.png\" ))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN.sample_images(train_latentcode,train_face,\"./model_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data_train/data_split/'\n",
    "with open(os.path.join(DATA_DIR,\"latentcode_val_augment.pkl\"), \"rb\") as input_file:\n",
    "    latentcode_augment = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"face_val_augment.pkl\"), \"rb\") as input_file:\n",
    "    face_augment = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"finger_val_augment.pkl\"), \"rb\") as input_file:\n",
    "    finger_augment = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 128), (300, 128, 128, 3), (300, 128, 128, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latentcode_augment[2].shape,face_augment.shape,finger_augment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "finger_augment = ((finger_augment)/np.max(finger_augment))\n",
    "finger_augment = np.where(finger_augment > .5, 1.0, -1.0).astype('float32')\n",
    "#finger_augment = ((finger_augment-127.5)/127.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c = 8, 4\n",
    "\n",
    "latentcode_datatrain = train_latentcode[200:500,:]\n",
    "y_true_datatrain = train_face[200:500,:,:,:]\n",
    "label_true_datatrain = label_train_finger[200:500,:,:,:]\n",
    "print(latentcode_datatrain.shape)\n",
    "noise_gauss = tf.keras.backend.random_normal(shape=(300, 128))\n",
    "gen_imgs_augment = GAN.generator.predict([latentcode_augment[2]+noise_gauss*0.2,finger_augment])\n",
    "\n",
    "# Perceptual loss\n",
    "perceptloss_augment = get_perceptual_loss(y_true_datatrain,gen_imgs_augment)\n",
    "\n",
    "indx = np.random.choice(y_true_datatrain.shape[0], int(0.5*c*r) ,replace=False)\n",
    "\n",
    "face_real = 0.5*(y_true_datatrain[indx]+1)\n",
    "face_real = face_real[:,:,:,[2,1,0]]\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs_augment[indx] + 1)\n",
    "gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "gen_imgs = gen_imgs[:,:,:,[2,1,0]]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,30))\n",
    "#fig.suptitle(\"Perceptual loss : %.3f\" %(perceptloss_augment))\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(int(0.25*c)):\n",
    "        axs[i,4*j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "        axs[i,4*j].axis('off')\n",
    "        axs[i,4*j+1].imshow(np.squeeze(face_real[cnt, :,:,:]))\n",
    "        axs[i,4*j+1].axis('off')\n",
    "        axs[i,4*j+2].imshow(np.squeeze(finger_augment[indx][cnt, :,:,:]),cmap='gray')\n",
    "        axs[i,4*j+2].axis('off')\n",
    "        axs[i,4*j+3].imshow(np.squeeze(label_true_datatrain[indx][cnt, :,:,:]),cmap='gray')\n",
    "        axs[i,4*j+3].axis('off')\n",
    "    cnt += 1\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(os.path.join('./model_save', \"images/face_gens_1.png\" ))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
