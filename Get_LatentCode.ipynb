{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, Input, LeakyReLU, Layer, UpSampling2D,Add,Flatten,AveragePooling2D, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_path = '../VAE_model/model_VAE/encoder_model_256.h5'\n",
    "decoder_model_path = '../VAE_model/model_VAE/decoder_model_256.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_encode = tf.keras.models.load_model(encoder_model_path, custom_objects={'Sampling': Sampling})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 64) 1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 128)  204928      conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 256)  819456      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 512)  3277312     conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 1024)   13108224    conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 65536)        0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 256)          16777472    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 256)          16777472    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 256)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50,966,528\n",
      "Trainable params: 50,966,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_encode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_decode = tf.keras.models.load_model(decoder_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 65536)             16842752  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 512)       13107712  \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       3277056   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 128)       819328    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 128, 128, 64)      204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 256, 256, 1)       1601      \n",
      "=================================================================\n",
      "Total params: 34,253,313\n",
      "Trainable params: 34,253,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_decode.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data fingerprint to encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../Finger_enhancement/data_cropped/data_train/\"\n",
    "\n",
    "with open(os.path.join(DATA_DIR,\"data_face_2856_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_fingerprint_2856_train.pkl\"), \"rb\") as input_file:\n",
    "    data_train_finger = pickle.load(input_file)\n",
    "\n",
    "    \n",
    "with open(os.path.join(DATA_DIR,\"data_face_2856_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"data_fingerprint_2856_val.pkl\"), \"rb\") as input_file:\n",
    "    data_val_finger = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2856, 256, 256, 3),\n",
       " (2856, 256, 256, 1),\n",
       " (715, 256, 256, 3),\n",
       " (715, 256, 256, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_face.shape,data_train_finger.shape,data_val_face.shape,data_val_finger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(data_3d):\n",
    "    num_data = data_3d.shape[0]\n",
    "    num_data_augment = int(data_3d.shape[0]*0.5)\n",
    "    index_data = np.random.choice(data_3d.shape[0],num_data_augment,replace=False)\n",
    "    data_aug = []\n",
    "    for i in index_data:\n",
    "        data_aug.append(data_3d[i,:,:,:])\n",
    "    samples = np.asarray(data_aug)    \n",
    "    \n",
    "\n",
    "    # create image data augmentation generator\n",
    "    datagen = ImageDataGenerator(horizontal_flip=False,height_shift_range=0.1,width_shift_range=0.1)\n",
    "    datagen.fit(samples)\n",
    "    it = datagen.flow(samples,batch_size=1000,shuffle=False)\n",
    "    results = np.concatenate([data_3d,it.next()],axis=0)\n",
    "    np.random.shuffle(results)\n",
    "    return results\n",
    "def augment_data_face_fingerprint(data_face,data_finger, num_augment_percent=0.5):\n",
    "    num_data = data_face.shape[0]\n",
    "    num_data_augment = int(data_face.shape[0]*num_augment_percent)\n",
    "    index_data = np.random.choice(data_face.shape[0],num_data_augment,replace=False)\n",
    "    \n",
    "    data_aug_face = []\n",
    "    data_aug_finger = []\n",
    "    for i in index_data:\n",
    "        data_aug_face.append(data_face[i,:,:,:])\n",
    "        data_aug_finger.append(data_finger[i,:,:,:])\n",
    "    data_aug_face = np.asarray(data_aug_face)    \n",
    "    data_aug_finger = np.asarray(data_aug_finger) \n",
    "\n",
    "    # create image data augmentation generator\n",
    "    datagen_face = ImageDataGenerator(horizontal_flip=True)\n",
    "    datagen_face.fit(data_aug_face)\n",
    "    \n",
    "    datagen_finger = ImageDataGenerator(horizontal_flip=False,height_shift_range=0.1,width_shift_range=0.1,shear_range=0.5,rotation_range=20)\n",
    "    datagen_finger.fit(data_aug_finger)\n",
    "    \n",
    "    it_face = datagen_face.flow(data_aug_face,batch_size=num_data_augment,shuffle=False)\n",
    "    it_finger = datagen_finger.flow(data_aug_finger,batch_size=num_data_augment,shuffle=False)\n",
    "    \n",
    "    results_face = np.concatenate([data_face,it_face.next()],axis=0)\n",
    "    results_finger = np.concatenate([data_finger,it_finger.next()],axis=0)\n",
    "    #np.random.shuffle(results)\n",
    "    return results_face,results_finger\n",
    "\n",
    "def add_noise_data(data_3d,noise_factor=1):\n",
    "    num_data = data_3d.shape[0]\n",
    "    num_data_add_noise = int(data_3d.shape[0]*0.3)\n",
    "    index_data = np.random.choice(data_3d.shape[0],num_data_add_noise,replace=False)\n",
    "    data_add_noise = []\n",
    "    for i in index_data:\n",
    "        data_add_noise.append(data_3d[i,:,:,:])\n",
    "    samples = np.asarray(data_add_noise)\n",
    "    data_none_noisy = np.asarray(data_add_noise)\n",
    "    data_noisy = samples + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=samples.shape)  \n",
    "    data_noisy = np.clip(data_noisy, 0., 1.)\n",
    "    return data_noisy,data_none_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_face, data_train_finger = augment_data_face_fingerprint(data_train_face,data_train_finger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4284, 256, 256, 3),\n",
       " (4284, 256, 256, 1),\n",
       " (715, 256, 256, 3),\n",
       " (715, 256, 256, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_face.shape,data_train_finger.shape,data_val_face.shape,data_val_finger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_finger = data_train_finger.astype('float32')\n",
    "data_train_finger = ((data_train_finger)/np.max(data_train_finger))\n",
    "data_train_finger = np.where(data_train_finger > .5, 1.0, 0.0).astype('float32')\n",
    "data_val_finger = data_val_finger.astype('float32')\n",
    "data_val_finger = ((data_val_finger)/np.max(data_val_finger))\n",
    "data_val_finger = np.where(data_val_finger > .5, 1.0, 0.0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_face = ((data_train_face-127.5)/127.5).astype('float32')\n",
    "data_val_face = ((data_val_face-127.5)/127.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(data_train_finger[0],cmap='gray')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow((data_train_face[0].astype('uint8')))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get latent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, logvar,z = model_encode.predict(data_finger_val)\n",
    "# result = [mean, logvar,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_finger = model_decode.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(data_finger_val[15])\n",
    "# plt.show()\n",
    "# plt.imshow(result_finger[15])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_finger_val = resize_image(data_finger_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_finger_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIR_SAVE = \"./data_train/data_split/\"\n",
    "# pickle.dump(result, open(os.path.join(DIR_SAVE,\"latentcode_val_augment.pkl\"),\"wb\"))\n",
    "# pickle.dump(data_face_val, open(os.path.join(DIR_SAVE,\"face_val_augment.pkl\"),\"wb\"))\n",
    "# pickle.dump(data_finger_val, open(os.path.join(DIR_SAVE,\"finger_val_augment.pkl\"),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train,logvar_train,z_train = model_encode.predict(data_train_finger)\n",
    "mean_val,logvar_val,z_val = model_encode.predict(data_val_finger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = model_decode.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_encoder_train = [mean_train,logvar_train,z_train]\n",
    "out_encoder_val = [mean_val,logvar_val,z_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_encoder_train = np.asarray(out_encoder_train)\n",
    "out_encoder_val = np.asarray(out_encoder_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4284, 256), (3, 715, 256))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder_train.shape,out_encoder_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_SAVE = \"./data_train/data_get_latent/\"\n",
    "pickle.dump(out_encoder_train, open(os.path.join(DIR_SAVE,\"data_latentcode_2856_train.pkl\"),\"wb\"))\n",
    "pickle.dump(out_encoder_val, open(os.path.join(DIR_SAVE,\"data_latentcode_2856_val.pkl\"),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 0.0\n",
      "1.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(data_train_finger),np.median(data_train_finger),np.min(data_train_finger))\n",
    "print(np.max(data_val_finger),np.median(data_val_finger),np.min(data_val_finger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_train_finger, open(os.path.join(DIR_SAVE,\"data_fingerprint_2856_train.pkl\"),\"wb\"))\n",
    "pickle.dump(data_train_face, open(os.path.join(DIR_SAVE,\"data_face_2856_train.pkl\"),\"wb\"))\n",
    "\n",
    "pickle.dump(data_val_finger, open(os.path.join(DIR_SAVE,\"data_fingerprint_2856_val.pkl\"),\"wb\"))\n",
    "pickle.dump(data_val_face, open(os.path.join(DIR_SAVE,\"data_face_2856_val.pkl\"),\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
