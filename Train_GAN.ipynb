{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop,SGD\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "class Cut_VGG19:\n",
    "    \"\"\"\n",
    "    Class object that fetches keras' VGG19 model trained on the imagenet dataset\n",
    "    and declares <layers_to_extract> as output layers. Used as feature extractor\n",
    "    for the perceptual loss function.\n",
    "    Args:\n",
    "        layers_to_extract: list of layers to be declared as output layers.\n",
    "        patch_size: integer, defines the size of the input (patch_size x patch_size).\n",
    "    Attributes:\n",
    "        loss_model: multi-output vgg architecture with <layers_to_extract> as output layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size, layers_to_extract):\n",
    "        self.patch_size = patch_size\n",
    "        self.input_shape = (patch_size,) * 2 + (3,)\n",
    "        self.layers_to_extract = layers_to_extract\n",
    "        \n",
    "        if len(self.layers_to_extract) > 0:\n",
    "            self._cut_vgg()\n",
    "    \n",
    "    def _cut_vgg(self):\n",
    "        \"\"\"\n",
    "        Loads pre-trained VGG, declares as output the intermediate\n",
    "        layers selected by self.layers_to_extract.\n",
    "        \"\"\"\n",
    "        \n",
    "        vgg = VGG19(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        vgg.trainable = False\n",
    "        outputs = [vgg.layers[i].output for i in self.layers_to_extract]\n",
    "        self.model = Model([vgg.input], outputs)\n",
    "\n",
    "        \n",
    "feature_extraction = Cut_VGG19(128,[5,9])   \n",
    "feature_extraction.model.trainable = False\n",
    "def get_perceptual_loss(y_true,y_pred):\n",
    "    content_feature = feature_extraction.model(y_true)\n",
    "    new_feature = feature_extraction.model(y_pred)\n",
    "    perceptual_loss = 0\n",
    "    weight = tf.constant([1/16,1/8], dtype = tf.float32)\n",
    "    for i in range(len(new_feature)):\n",
    "        perceptual_loss += weight[i]*K.mean(K.square(new_feature[i] - content_feature[i]))\n",
    "    l2_loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true,y_pred))\n",
    "    total_loss = perceptual_loss + 15*l2_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGP():\n",
    "    def __init__(self):\n",
    "        self.input_dim = (128,128,3)\n",
    "        self.critic_conv_filters = [16,32,64,128]\n",
    "        self.critic_conv_kernel_size = [3,3,3,3]\n",
    "        self.critic_conv_strides = [2,2,2,2]\n",
    "        self.critic_batch_norm_momentum = None\n",
    "        self.critic_activation = 'leaky_relu'\n",
    "        self.critic_dropout_rate = None\n",
    "        self.critic_learning_rate = 1e-3\n",
    "        \n",
    "\n",
    "        self.generator_initial_dense_layer_size = (4,4, 128)\n",
    "        self.generator_upsample = [1,1,1,1,1]\n",
    "        self.generator_conv_filters = [128,64,32,16,3]\n",
    "        self.generator_conv_kernel_size = [3,3,3,3,3]\n",
    "        self.generator_conv_strides = [2,2,2,2,2]\n",
    "        self.generator_batch_norm_momentum =  0.8\n",
    "        self.generator_activation = 'leaky_relu'\n",
    "        self.generator_dropout_rate = None\n",
    "        self.generator_learning_rate = 1e-3\n",
    "        \n",
    "        self.optimiser = 'rmsprop'\n",
    "\n",
    "        self.z_dim = 128\n",
    "\n",
    "        self.n_layers_critic = len(self.critic_conv_filters)\n",
    "        self.n_layers_generator = len(self.generator_conv_filters)\n",
    "\n",
    "        self.weight_init = RandomNormal(mean=0., stddev=0.02) # 'he_normal' #RandomNormal(mean=0., stddev=0.02)\n",
    "        self.grad_weight = 10\n",
    "        self.batch_size = 128\n",
    "\n",
    "\n",
    "        self.d_losses = []\n",
    "        self.g_losses = []\n",
    "        self.epoch = 0\n",
    "\n",
    "        self._build_critic()\n",
    "        self._build_generator()\n",
    "\n",
    "        self._build_adversarial()\n",
    "        \n",
    "#     def gradient_penalty_loss(self, y_true, y_pred, interpolated_samples):\n",
    "#         gradients = K.gradients(y_pred, interpolated_samples)[0]\n",
    "\n",
    "#         # compute the euclidean norm by squaring ...\n",
    "#         gradients_sqr = K.square(gradients)\n",
    "#         #   ... summing over the rows ...\n",
    "#         gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "#                                   axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "#         #   ... and sqrt\n",
    "#         gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "#         # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "#         gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "#         # return the mean as loss over all the batch samples\n",
    "#         return K.mean(gradient_penalty)\n",
    "\n",
    "    def gradient_penalty_loss(self,y_true, y_pred, discriminator,gradient_penalty_weight):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "      \n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(y_pred)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = discriminator(y_pred, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [y_pred])[0]\n",
    "        # 3. Calcuate the norm of the gradients\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp*gradient_penalty_weight\n",
    "    \n",
    "    \n",
    "    def wasserstein(self, y_true, y_pred):\n",
    "        return -K.mean(y_true * y_pred)\n",
    "    \n",
    "    def get_activation(self, activation):\n",
    "        if activation == 'leaky_relu':\n",
    "            layer = LeakyReLU(alpha = 0.2)\n",
    "        else:\n",
    "            layer = Activation(activation)\n",
    "        return layer\n",
    "    \n",
    "    def _build_critic(self):\n",
    "        critic_input = Input(shape=self.input_dim, name='critic_input')\n",
    "        x = critic_input\n",
    "\n",
    "        for i in range(self.n_layers_critic):\n",
    "            x = Conv2D(\n",
    "                filters = self.critic_conv_filters[i]\n",
    "                , kernel_size = self.critic_conv_kernel_size[i]\n",
    "                , strides = self.critic_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'critic_conv_' + str(i)\n",
    "                , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "\n",
    "            if self.critic_batch_norm_momentum and i > 0:\n",
    "                x = BatchNormalization(momentum = self.critic_batch_norm_momentum)(x)\n",
    "            x = self.get_activation(self.critic_activation)(x)\n",
    "            if self.critic_dropout_rate:\n",
    "                x = Dropout(rate = self.critic_dropout_rate)(x)\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        critic_output = Dense(1, activation=None\n",
    "        , kernel_initializer = self.weight_init\n",
    "        )(x)\n",
    "\n",
    "        self.critic = Model(critic_input, critic_output)\n",
    "        \n",
    "    def _build_generator(self):\n",
    "\n",
    "        ### THE generator\n",
    "\n",
    "        generator_input = Input(shape=(self.z_dim,), name='generator_input')\n",
    "\n",
    "        x = generator_input\n",
    "\n",
    "        x = Dense(np.prod(self.generator_initial_dense_layer_size), kernel_initializer = self.weight_init)(x)\n",
    "        \n",
    "        if self.generator_batch_norm_momentum:\n",
    "            x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "        \n",
    "        x = self.get_activation(self.generator_activation)(x)\n",
    "\n",
    "        x = Reshape(self.generator_initial_dense_layer_size)(x)\n",
    "\n",
    "        if self.generator_dropout_rate:\n",
    "            x = Dropout(rate = self.generator_dropout_rate)(x)\n",
    "\n",
    "        for i in range(self.n_layers_generator):\n",
    "\n",
    "            if self.generator_upsample[i] == 2:\n",
    "                x = UpSampling2D()(x)\n",
    "                x = Conv2D(\n",
    "                filters = self.generator_conv_filters[i]\n",
    "                , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'generator_conv_' + str(i)\n",
    "                , kernel_initializer = self.weight_init\n",
    "                )(x)\n",
    "            else:\n",
    "\n",
    "                x = Conv2DTranspose(\n",
    "                    filters = self.generator_conv_filters[i]\n",
    "                    , kernel_size = self.generator_conv_kernel_size[i]\n",
    "                    , padding = 'same'\n",
    "                    , strides = self.generator_conv_strides[i]\n",
    "                    , name = 'generator_conv_' + str(i)\n",
    "                    , kernel_initializer = self.weight_init\n",
    "                    )(x)\n",
    "\n",
    "            if i < self.n_layers_generator - 1:\n",
    "\n",
    "                if self.generator_batch_norm_momentum:\n",
    "                    x = BatchNormalization(momentum = self.generator_batch_norm_momentum)(x)\n",
    "\n",
    "                x = self.get_activation(self.generator_activation)(x)\n",
    "                \n",
    "            else:\n",
    "                x = Activation('tanh')(x)\n",
    "\n",
    "        generator_output = x\n",
    "        self.generator = Model(generator_input, generator_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_opti(self, lr):\n",
    "        if self.optimiser == 'adam':\n",
    "            opti = Adam(lr=lr, beta_1=0.5)\n",
    "        elif self.optimiser == 'rmsprop':\n",
    "            opti = RMSprop(lr=lr)\n",
    "        else:\n",
    "            opti = Adam(lr=lr)\n",
    "\n",
    "        return opti\n",
    "\n",
    "\n",
    "    def set_trainable(self, m, val):\n",
    "        m.trainable = val\n",
    "        for l in m.layers:\n",
    "            l.trainable = val\n",
    "\n",
    "    def _build_adversarial(self):\n",
    "                \n",
    "        self.critic.compile(\n",
    "            optimizer=self.get_opti(self.critic_learning_rate) \n",
    "            , loss = self.wasserstein\n",
    "        )\n",
    "        \n",
    "        ### COMPILE THE FULL GAN\n",
    "\n",
    "        self.set_trainable(self.critic, False)\n",
    "\n",
    "        model_input = Input(shape=(self.z_dim,), name='model_input')\n",
    "        model_output = self.critic(self.generator(model_input))\n",
    "        self.model = Model(model_input, model_output)\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=self.get_opti(self.generator_learning_rate)\n",
    "            , loss=self.wasserstein\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.generator.compile(\n",
    "            optimizer=self.get_opti(self.generator_learning_rate)\n",
    "            , loss=get_perceptual_loss\n",
    "            )\n",
    "\n",
    "        self.set_trainable(self.critic, True)\n",
    "        \n",
    "    def train_critic(self, x_train,Y_train, batch_size, using_generator):\n",
    "\n",
    "        valid = np.ones((batch_size,1))\n",
    "        fake = -np.ones((batch_size,1))\n",
    "\n",
    "        if using_generator:\n",
    "            true_imgs = next(Y_train)\n",
    "            if true_imgs.shape[0] != batch_size:\n",
    "                true_imgs = next(Y_train)\n",
    "        else:\n",
    "            idx = np.random.randint(0, Y_train.shape[0], batch_size)\n",
    "            true_imgs = Y_train[idx]\n",
    "        \n",
    "        \n",
    "        #noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        noise = next(x_train)\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        g_perceptual = self.generator.train_on_batch(noise,true_imgs)\n",
    "        \n",
    "        d_loss_real =   self.critic.train_on_batch(true_imgs, valid)\n",
    "        d_loss_fake =   self.critic.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "\n",
    "        for l in self.critic.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "\n",
    "        for l in self.critic.layers:\n",
    "        \n",
    "            weights = l.get_weights()\n",
    "            if 'batch_normalization' in l.get_config()['name']:\n",
    "                pass\n",
    "                # weights = [np.clip(w, -0.01, 0.01) for w in weights[:2]] + weights[2:]\n",
    "            else:\n",
    "                weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "            \n",
    "            l.set_weights(weights)\n",
    "\n",
    "        return [d_loss, d_loss_real, d_loss_fake, g_perceptual]\n",
    "\n",
    "    def train_generator(self,x_train, batch_size):\n",
    "        valid = np.ones((batch_size,1), dtype=np.float32)\n",
    "        noise = next(x_train)\n",
    "        #noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
    "        return self.model.train_on_batch(noise, valid)\n",
    "\n",
    "    def load_random_batch(self,X_train,Y_train,batch_size):\n",
    "        num_image = X_train.shape[0]\n",
    "        random_samples_indices = np.random.choice(num_image, batch_size,replace=False)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in random_samples_indices:\n",
    "            X.append(X_train[i])\n",
    "            Y.append(Y_train[i])\n",
    "        X = iter(np.asarray(X))\n",
    "        Y = iter(np.asarray(Y))\n",
    "        return X,Y\n",
    "    \n",
    "    def shuffle_data_batch(self,array_X,array_Y,batch_size):\n",
    "        indices = np.arange(array_X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        array_X = array_X[indices]\n",
    "        array_Y = array_Y[indices]\n",
    "        def split_into_chunks(l, n):\n",
    "            for i in range(0, l.shape[0], n):\n",
    "                yield l[i:i + n]  \n",
    "        array_X = split_into_chunks(array_X,batch_size)\n",
    "        array_Y = split_into_chunks(array_Y,batch_size)\n",
    "        return array_X,array_Y\n",
    "\n",
    "    def train(self, x_train,Y_train,x_val,Y_val, batch_size, epochs, run_folder, print_every_n_batches = 10, n_critic = 5,using_generator = False):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        for epoch in range(self.epoch, self.epoch + epochs):\n",
    "            x_train_wgan,Y_train_wgan = self.shuffle_data_batch(x_train,Y_train,batch_size)\n",
    "            for _ in range(n_critic):\n",
    "                d_loss = self.train_critic(x_train_wgan,Y_train_wgan, batch_size, using_generator)\n",
    "\n",
    "            g_loss = self.train_generator(x_train_wgan,batch_size)\n",
    "               \n",
    "            # Plot the progress\n",
    "            \n",
    "            self.d_losses.append(d_loss)\n",
    "            self.g_losses.append(g_loss)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % print_every_n_batches == 0:\n",
    "                print (\"%d [D loss: (%.3f)(R %.3f, F %.3f) Per %.3f]  [G loss: %.3f] \" % (epoch, d_loss[0], d_loss[1], d_loss[2],d_loss[3], g_loss))\n",
    "                self.sample_images(x_val,Y_val,run_folder)\n",
    "                #self.model.save_weights(os.path.join(run_folder, 'weights/weights-%d.h5' % (epoch)))\n",
    "                #self.model.save_weights(os.path.join(run_folder, 'weights/weights.h5'))\n",
    "                #self.save_model(run_folder)\n",
    "            \n",
    "            self.epoch+=1\n",
    "\n",
    "\n",
    "\n",
    "    def sample_images(self,x_val,Y_val, run_folder):\n",
    "        # Test\n",
    "        r, c = 4, 4\n",
    "\n",
    "        latent_code = x_val[:100,:]\n",
    "        y_true = Y_val[:100,:,:,:]\n",
    "\n",
    "        gen_imgs = self.generator.predict(latent_code)\n",
    "        # Perceptual loss\n",
    "        perceptloss = get_perceptual_loss(y_true,gen_imgs)\n",
    "\n",
    "        indx = np.random.choice(y_true.shape[0], int(0.5*c*r) ,replace=False)\n",
    "\n",
    "        face_real = 0.5*(y_true[indx]+1)\n",
    "        face_real = face_real[:,:,:,[2,1,0]]\n",
    "\n",
    "        gen_imgs = 0.5 * (gen_imgs[indx] + 1)\n",
    "        gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "        gen_imgs = gen_imgs[:,:,:,[2,1,0]]\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "        fig.suptitle(\"Perceptual loss : %.3f\" %(perceptloss))\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(int(0.5*c)):\n",
    "                axs[i,2*j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "                axs[i,2*j].axis('off')\n",
    "                axs[i,2*j+1].imshow(np.squeeze(face_real[cnt, :,:,:]))\n",
    "                axs[i,2*j+1].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(os.path.join(run_folder, \"images_latent/sample_%d.png\" % self.epoch))\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN = WGANGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_input (InputLayer)    [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "critic_conv_0 (Conv2D)       (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_1 (Conv2D)       (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_2 (Conv2D)       (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "critic_conv_3 (Conv2D)       (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 105,633\n",
      "Trainable params: 105,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              264192    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2DTran (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2DTran (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 32, 32, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 64, 64, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_4 (Conv2DTran (None, 128, 128, 3)       435       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 518,243\n",
      "Trainable params: 513,667\n",
      "Non-trainable params: 4,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data_train/data_split/'\n",
    "with open(os.path.join(DATA_DIR,\"data_train_face_train_3channels.pkl\"), \"rb\") as input_file:\n",
    "    data_train_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"latentcode_finger_train_3channels.pkl\"), \"rb\") as input_file:\n",
    "    data_train_latentcode = pickle.load(input_file)\n",
    "    \n",
    "with open(os.path.join(DATA_DIR,\"data_train_face_val_3channels.pkl\"), \"rb\") as input_file:\n",
    "    data_val_face = pickle.load(input_file)\n",
    "with open(os.path.join(DATA_DIR,\"latentcode_finger_val_3channels.pkl\"), \"rb\") as input_file:\n",
    "    data_val_latentcode = pickle.load(input_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_face = ((data_train_face-127.5)/127.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1802, 128, 128, 3), (1802, 128))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_face.shape,data_train_latentcode[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val_face = ((data_val_face-127.5)/127.5).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 128, 128, 3), (150, 128))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_face.shape,data_val_latentcode[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_latentcode = data_train_latentcode[2]\n",
    "train_face = data_train_face\n",
    "valid_latentcode = data_val_latentcode[2]\n",
    "valid_face = data_val_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_latentcode,valid_latentcode,train_face,valid_face = train_test_split(data_train_latentcode[2],\n",
    "#                                                              data_train_face,\n",
    "#                                                              test_size=0.2,\n",
    "#                                                              random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1802, 128), (150, 128), (1802, 128, 128, 3), (150, 128, 128, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_latentcode.shape,valid_latentcode.shape,train_face.shape,valid_face.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GAN.train(  \n",
    "      train_latentcode\n",
    "    , train_face\n",
    "    , valid_latentcode\n",
    "    , valid_face\n",
    "    , batch_size = 256\n",
    "    , epochs = 10000\n",
    "    , run_folder = './model_save'\n",
    "    , print_every_n_batches = 50\n",
    "    , n_critic = 5\n",
    "    , using_generator = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN.critic.save('./model_save/model/discriminator_3channel_068.h5')\n",
    "# GAN.generator.save('./model_save/model/generator_3channel_068.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = tf.keras.models.load_model('./model_save/model/generator_3channel_068.h5',custom_objects={'get_perceptual_loss': get_perceptual_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data_train/data_split/'\n",
    "with open(os.path.join(DATA_DIR,\"latentcode_finger_longthieu.pkl\"), \"rb\") as input_file:\n",
    "    latent_longthieu = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_longthieu[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "r, c = 2, 2\n",
    "\n",
    "latent_code = latent_longthieu[2]\n",
    "\n",
    "gen_imgs = GAN.generator.predict(latent_code)\n",
    "\n",
    "\n",
    "gen_imgs = 0.5 * (gen_imgs + 1)\n",
    "gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "gen_imgs = gen_imgs[:,:,:,[2,1,0]]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(int(c)):\n",
    "        axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "        #axs[i,2*j].axis('off')\n",
    "        cnt += 1\n",
    "# plt.imshow(gen_imgs[1])\n",
    "# plt.show()\n",
    "# #fig.savefig(os.path.join('./model_save', \"images/face_gens.png\" ))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# r, c = 4, 4\n",
    "\n",
    "# latent_code = valid_latentcode[:100,:]\n",
    "# y_true = valid_face[:100,:,:,:]\n",
    "\n",
    "# gen_imgs = GAN.generator.predict(latent_code)\n",
    "# # Perceptual loss\n",
    "# perceptloss = get_perceptual_loss(y_true,gen_imgs)\n",
    "\n",
    "# indx = np.random.choice(y_true.shape[0], int(0.5*c*r) ,replace=False)\n",
    "\n",
    "# face_real = 0.5*(y_true[indx]+1)\n",
    "# face_real = face_real[:,:,:,[2,1,0]]\n",
    "\n",
    "# gen_imgs = 0.5 * (gen_imgs[indx] + 1)\n",
    "# gen_imgs = np.clip(gen_imgs, 0, 1)\n",
    "# gen_imgs = gen_imgs[:,:,:,[2,1,0]]\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(r, c, figsize=(15,15))\n",
    "# fig.suptitle(\"Perceptual loss : %.3f\" %(perceptloss))\n",
    "# cnt = 0\n",
    "# for i in range(r):\n",
    "#     for j in range(int(0.5*c)):\n",
    "#         axs[i,2*j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]))\n",
    "#         #axs[i,2*j].axis('off')\n",
    "#         axs[i,2*j+1].imshow(np.squeeze(face_real[cnt, :,:,:]))\n",
    "#         #axs[i,2*j+1].axis('off')\n",
    "#         cnt += 1\n",
    "\n",
    "# plt.show()\n",
    "# #fig.savefig(os.path.join('./model_save', \"images/face_gens.png\" ))\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAN.sample_images(train_latentcode,train_face,\"./model_save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
